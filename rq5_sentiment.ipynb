{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ5: Evaluative tone by document type and over time\n",
    "\n",
    "This notebook analyses how evaluative tone differs between motioner (MP proposals) and propositioner (government bills), and how sentiment has changed over parliamentary years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation settings\n",
    "plt.rcParams['font.family'] = 'monospace'\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.labelsize'] = 10\n",
    "plt.rcParams['axes.titlesize'] = 11\n",
    "plt.rcParams['xtick.labelsize'] = 9\n",
    "plt.rcParams['ytick.labelsize'] = 9\n",
    "plt.rcParams['legend.fontsize'] = 9\n",
    "\n",
    "# purple/pink colour palette\n",
    "COLOUR_MOT = '#9B59B6'  # purple\n",
    "COLOUR_PROP = '#E91E63'  # pink\n",
    "COLOUR_PALETTE = [COLOUR_MOT, COLOUR_PROP]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_document(file_path):\n",
    "    \"\"\"extract metadata and content from document file.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # split metadata from content\n",
    "    parts = content.split('=' * 80, 1)\n",
    "    if len(parts) != 2:\n",
    "        return None\n",
    "    \n",
    "    metadata_section, html_content = parts\n",
    "    \n",
    "    # extract metadata fields\n",
    "    metadata = {}\n",
    "    for line in metadata_section.strip().split('\\n'):\n",
    "        if ':' in line:\n",
    "            key, value = line.split(':', 1)\n",
    "            metadata[key.strip()] = value.strip()\n",
    "    \n",
    "    # extract plain text from html\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    text = soup.get_text(separator=' ', strip=True)\n",
    "    \n",
    "    return {\n",
    "        'doc_id': metadata.get('DOCUMENT ID', ''),\n",
    "        'title': metadata.get('TITLE', ''),\n",
    "        'date': metadata.get('DATE', ''),\n",
    "        'parl_year': metadata.get('PARLIAMENTARY YEAR', ''),\n",
    "        'text': text\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load motioner\n",
    "data_dir = Path('/Users/simon/Dropbox/wrk/active/research/riksdagen-data/swe-rd-ai/data')\n",
    "motioner_dir = data_dir / 'motioner'\n",
    "propositioner_dir = data_dir / 'propositioner'\n",
    "\n",
    "documents = []\n",
    "\n",
    "# load motioner\n",
    "for file_path in motioner_dir.glob('*.txt'):\n",
    "    doc = parse_document(file_path)\n",
    "    if doc:\n",
    "        doc['doc_type'] = 'mot'\n",
    "        documents.append(doc)\n",
    "\n",
    "# load propositioner\n",
    "for file_path in propositioner_dir.glob('*.txt'):\n",
    "    doc = parse_document(file_path)\n",
    "    if doc:\n",
    "        doc['doc_type'] = 'prop'\n",
    "        documents.append(doc)\n",
    "\n",
    "df = pd.DataFrame(documents)\n",
    "print(f\"loaded {len(df)} documents\")\n",
    "print(f\"  motioner: {len(df[df['doc_type'] == 'mot'])}\")\n",
    "print(f\"  propositioner: {len(df[df['doc_type'] == 'prop'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai search patterns\n",
    "ai_patterns = [\n",
    "    r'\\bai\\b',\n",
    "    r'artificiell intelligens',\n",
    "    r'maskininlärning',\n",
    "    r'maskinlärning',\n",
    "    r'djupinlärning',\n",
    "    r'deep learning',\n",
    "    r'machine learning'\n",
    "]\n",
    "\n",
    "ai_regex = re.compile('|'.join(ai_patterns), re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ai_contexts(text, window=100):\n",
    "    \"\"\"extract text windows around ai mentions.\"\"\"\n",
    "    contexts = []\n",
    "    \n",
    "    for match in ai_regex.finditer(text):\n",
    "        start = max(0, match.start() - window)\n",
    "        end = min(len(text), match.end() + window)\n",
    "        context = text[start:end]\n",
    "        contexts.append(context)\n",
    "    \n",
    "    return contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract contexts for all documents\n",
    "df['ai_contexts'] = df['text'].apply(extract_ai_contexts)\n",
    "df['context_count'] = df['ai_contexts'].apply(len)\n",
    "df['combined_context'] = df['ai_contexts'].apply(lambda x: ' '.join(x).lower())\n",
    "\n",
    "print(f\"total ai mentions: {df['context_count'].sum()}\")\n",
    "print(f\"documents with ai mentions: {len(df[df['context_count'] > 0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swedish sentiment lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive word list\n",
    "positive_words = [\n",
    "    'bra', 'positiv', 'möjlighet', 'möjligheter', 'framgång', 'effektiv', \n",
    "    'förbättra', 'förbättring', 'utveckla', 'utveckling', 'framsteg', \n",
    "    'fördelar', 'fördel', 'potential', 'styrka', 'lovande', 'framtid',\n",
    "    'nytta', 'gynnsam', 'värdefull', 'innovation', 'innovativ',\n",
    "    'produktiv', 'produktivitet', 'konkurrenskraft', 'konkurrenskraftig'\n",
    "]\n",
    "\n",
    "# negative word list\n",
    "negative_words = [\n",
    "    'problem', 'risk', 'risker', 'hot', 'oro', 'svårt', 'svårighet',\n",
    "    'utmaning', 'utmaningar', 'nackdel', 'nackdelar', 'brist', 'brister',\n",
    "    'hinder', 'fara', 'faror', 'missbruk', 'kris', 'sårbar', 'sårbarhet',\n",
    "    'negativ', 'negativa', 'osäkerhet', 'konflikt', 'bekymmer'\n",
    "]\n",
    "\n",
    "print(f\"positive words: {len(positive_words)}\")\n",
    "print(f\"negative words: {len(negative_words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_sentiment_words(text, word_list):\n",
    "    \"\"\"count occurrences of words from word_list in text.\"\"\"\n",
    "    count = 0\n",
    "    for word in word_list:\n",
    "        # word boundary matching\n",
    "        pattern = r'\\b' + re.escape(word) + r'\\b'\n",
    "        count += len(re.findall(pattern, text, re.IGNORECASE))\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate sentiment scores\n",
    "df['positive_count'] = df['combined_context'].apply(\n",
    "    lambda x: count_sentiment_words(x, positive_words)\n",
    ")\n",
    "df['negative_count'] = df['combined_context'].apply(\n",
    "    lambda x: count_sentiment_words(x, negative_words)\n",
    ")\n",
    "\n",
    "# calculate sentiment ratio normalised by context length\n",
    "df['context_length'] = df['combined_context'].apply(len)\n",
    "df['sentiment_ratio'] = (df['positive_count'] - df['negative_count']) / (df['context_length'] + 1) * 1000\n",
    "\n",
    "# filter to documents with ai mentions\n",
    "df_with_ai = df[df['context_count'] > 0].copy()\n",
    "\n",
    "print(f\"documents with ai mentions: {len(df_with_ai)}\")\n",
    "print(f\"\\nsentiment statistics:\")\n",
    "print(df_with_ai[['positive_count', 'negative_count', 'sentiment_ratio']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean parliamentary year format\n",
    "df_with_ai['year_clean'] = df_with_ai['parl_year'].str.split('/').str[0]\n",
    "df_with_ai['year_clean'] = pd.to_numeric(df_with_ai['year_clean'], errors='coerce')\n",
    "\n",
    "# filter valid years\n",
    "df_temporal = df_with_ai[df_with_ai['year_clean'].notna()].copy()\n",
    "\n",
    "# group by year and document type\n",
    "temporal_sentiment = df_temporal.groupby(['year_clean', 'doc_type']).agg({\n",
    "    'sentiment_ratio': 'mean',\n",
    "    'doc_id': 'count'\n",
    "}).reset_index()\n",
    "temporal_sentiment.columns = ['year', 'doc_type', 'mean_sentiment', 'doc_count']\n",
    "\n",
    "temporal_sentiment.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box plot comparing sentiment distributions by document type\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "mot_data = df_with_ai[df_with_ai['doc_type'] == 'mot']['sentiment_ratio']\n",
    "prop_data = df_with_ai[df_with_ai['doc_type'] == 'prop']['sentiment_ratio']\n",
    "\n",
    "positions = [1, 2]\n",
    "bp = ax.boxplot(\n",
    "    [mot_data, prop_data],\n",
    "    positions=positions,\n",
    "    widths=0.6,\n",
    "    patch_artist=True,\n",
    "    medianprops={'color': 'black', 'linewidth': 1.5},\n",
    "    boxprops={'facecolor': 'lightgrey', 'edgecolor': 'black'},\n",
    "    whiskerprops={'color': 'black'},\n",
    "    capprops={'color': 'black'}\n",
    ")\n",
    "\n",
    "# colour boxes\n",
    "bp['boxes'][0].set_facecolor(COLOUR_MOT)\n",
    "bp['boxes'][1].set_facecolor(COLOUR_PROP)\n",
    "\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(['motioner', 'propositioner'])\n",
    "ax.set_ylabel('sentiment ratio (per 1000 chars)')\n",
    "ax.set_title('Sentiment distribution by document type')\n",
    "ax.axhline(y=0, color='grey', linestyle='--', linewidth=0.8, alpha=0.5)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Users/simon/Dropbox/wrk/active/research/riksdagen-data/swe-rd-ai/results/rq5_sentiment_boxplot.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line chart of sentiment over time by type\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "for doc_type, colour in [('mot', COLOUR_MOT), ('prop', COLOUR_PROP)]:\n",
    "    data = temporal_sentiment[temporal_sentiment['doc_type'] == doc_type]\n",
    "    ax.plot(data['year'], data['mean_sentiment'], \n",
    "            marker='o', color=colour, linewidth=2, markersize=6,\n",
    "            label='motioner' if doc_type == 'mot' else 'propositioner')\n",
    "\n",
    "ax.axhline(y=0, color='grey', linestyle='--', linewidth=0.8, alpha=0.5)\n",
    "ax.set_xlabel('parliamentary year')\n",
    "ax.set_ylabel('mean sentiment ratio')\n",
    "ax.set_title('Sentiment over time by document type')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Users/simon/Dropbox/wrk/active/research/riksdagen-data/swe-rd-ai/results/rq5_sentiment_timeline.png',\n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of sentiment score distributions\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 6), sharex=True)\n",
    "\n",
    "# motioner\n",
    "axes[0].hist(mot_data, bins=30, color=COLOUR_MOT, alpha=0.7, edgecolor='black')\n",
    "axes[0].axvline(mot_data.mean(), color='black', linestyle='--', linewidth=1.5)\n",
    "axes[0].set_ylabel('frequency')\n",
    "axes[0].set_title('motioner sentiment distribution')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# propositioner\n",
    "axes[1].hist(prop_data, bins=30, color=COLOUR_PROP, alpha=0.7, edgecolor='black')\n",
    "axes[1].axvline(prop_data.mean(), color='black', linestyle='--', linewidth=1.5)\n",
    "axes[1].set_xlabel('sentiment ratio (per 1000 chars)')\n",
    "axes[1].set_ylabel('frequency')\n",
    "axes[1].set_title('propositioner sentiment distribution')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Users/simon/Dropbox/wrk/active/research/riksdagen-data/swe-rd-ai/results/rq5_sentiment_histogram.png',\n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary statistics by document type\n",
    "summary_stats = df_with_ai.groupby('doc_type').agg({\n",
    "    'sentiment_ratio': ['mean', 'median', 'std', 'count'],\n",
    "    'positive_count': 'mean',\n",
    "    'negative_count': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "print(\"sentiment statistics by document type:\")\n",
    "print(summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mann-whitney u test for difference in sentiment distributions\n",
    "statistic, p_value = stats.mannwhitneyu(mot_data, prop_data, alternative='two-sided')\n",
    "\n",
    "print(f\"\\nmann-whitney u test:\")\n",
    "print(f\"  statistic: {statistic:.2f}\")\n",
    "print(f\"  p-value: {p_value:.4f}\")\n",
    "print(f\"  significant at α=0.05: {p_value < 0.05}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# effect size (cohen's d)\n",
    "mean_diff = mot_data.mean() - prop_data.mean()\n",
    "pooled_std = np.sqrt((mot_data.std()**2 + prop_data.std()**2) / 2)\n",
    "cohens_d = mean_diff / pooled_std\n",
    "\n",
    "print(f\"\\neffect size (cohen's d): {cohens_d:.3f}\")\n",
    "if abs(cohens_d) < 0.2:\n",
    "    effect = 'negligible'\n",
    "elif abs(cohens_d) < 0.5:\n",
    "    effect = 'small'\n",
    "elif abs(cohens_d) < 0.8:\n",
    "    effect = 'medium'\n",
    "else:\n",
    "    effect = 'large'\n",
    "print(f\"  interpretation: {effect}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare export data\n",
    "export_df = df_with_ai[[\n",
    "    'doc_id', 'doc_type', 'parl_year', 'title',\n",
    "    'context_count', 'positive_count', 'negative_count',\n",
    "    'context_length', 'sentiment_ratio'\n",
    "]].copy()\n",
    "\n",
    "# save to csv\n",
    "output_path = Path('/Users/simon/Dropbox/wrk/active/research/riksdagen-data/swe-rd-ai/results/rq5_sentiment.csv')\n",
    "export_df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"results exported to {output_path}\")\n",
    "print(f\"total documents: {len(export_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export temporal summary\n",
    "temporal_output = Path('/Users/simon/Dropbox/wrk/active/research/riksdagen-data/swe-rd-ai/results/rq5_sentiment_temporal.csv')\n",
    "temporal_sentiment.to_csv(temporal_output, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"temporal summary exported to {temporal_output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
