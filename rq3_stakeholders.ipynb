{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ3: Stakeholder invocation analysis\n",
    "\n",
    "This notebook examines which actors are invoked in AI-related parliamentary discourse: institutional actors (EU, state, industry, experts) versus citizen-focused actors (individuals, workers, communities, vulnerable groups). We compare motioner (MP proposals, bottom-up) against propositioner (government bills, top-down) to test whether government texts privilege institutional actors whilst MP proposals centre citizens and communities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import re\nfrom pathlib import Path\nfrom collections import defaultdict\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom bs4 import BeautifulSoup\n\n# set visualisation style\nplt.rcParams['font.family'] = 'monospace'\nplt.rcParams['font.size'] = 10\nsns.set_palette(['#9B59B6', '#E91E63', '#555555', '#AAAAAA'])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "Parse document metadata headers and extract clean text from HTML content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_document(file_path):\n",
    "    \"\"\"extract metadata and clean text from parliamentary document.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # split metadata from html content\n",
    "    parts = content.split('=' * 80)\n",
    "    if len(parts) < 2:\n",
    "        return None\n",
    "    \n",
    "    metadata_section = parts[0]\n",
    "    html_content = parts[1]\n",
    "    \n",
    "    # parse metadata\n",
    "    metadata = {}\n",
    "    for line in metadata_section.strip().split('\\n'):\n",
    "        if ':' in line:\n",
    "            key, value = line.split(':', 1)\n",
    "            metadata[key.strip().lower().replace(' ', '_')] = value.strip()\n",
    "    \n",
    "    # extract text from html\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    text = soup.get_text(separator=' ', strip=True)\n",
    "    \n",
    "    # clean text\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'Observera att dokumentet är inskannat.*?förekomma\\.?', '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    return {\n",
    "        'document_id': metadata.get('document_id', ''),\n",
    "        'title': metadata.get('title', ''),\n",
    "        'type': metadata.get('type', ''),\n",
    "        'date': metadata.get('date', ''),\n",
    "        'parliamentary_year': metadata.get('parliamentary_year', ''),\n",
    "        'text': text.strip(),\n",
    "        'word_count': len(text.split())\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# load motioner\nmotioner_dir = Path('/Users/simon/Dropbox/wrk/active/research/riksdagen-data/swe-rd-ai/data/motioner')\nmotioner_files = list(motioner_dir.glob('*.txt'))\n\nmotioner_data = []\nfor file_path in motioner_files:\n    doc = parse_document(file_path)\n    if doc and doc['word_count'] > 50:  # exclude very short documents\n        doc['doc_type'] = 'mot'\n        motioner_data.append(doc)\n\nprint(f\"loaded {len(motioner_data)} motioner\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# load propositioner\nprop_dir = Path('/Users/simon/Dropbox/wrk/active/research/riksdagen-data/swe-rd-ai/data/propositioner')\nprop_files = list(prop_dir.glob('*.txt'))\n\nprop_data = []\nfor file_path in prop_files:\n    doc = parse_document(file_path)\n    if doc and doc['word_count'] > 50:\n        doc['doc_type'] = 'prop'\n        prop_data.append(doc)\n\nprint(f\"loaded {len(prop_data)} propositioner\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# combine into single dataframe\ndf = pd.DataFrame(motioner_data + prop_data)\ndf['text_lower'] = df['text'].str.lower()\n\nprint(f\"\\ntotal corpus: {len(df)} documents\")\nprint(f\"motioner: {len(df[df['doc_type'] == 'mot'])}\")\nprint(f\"propositioner: {len(df[df['doc_type'] == 'prop'])}\")\nprint(f\"\\ntotal words: {df['word_count'].sum():,}\")\nprint(f\"mean document length: {df['word_count'].mean():.0f} words\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stakeholder dictionaries\n",
    "\n",
    "Define keyword patterns for institutional versus citizen-focused actors. Keywords are matched as word boundaries to avoid substring matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# institutional actors\n",
    "stakeholder_keywords = {\n",
    "    # institutional\n",
    "    'eu_international': [\n",
    "        r'\\beu\\b', r'\\beus\\b', r'europeisk', r'europa', r'union', r'kommissionen', \n",
    "        r'europaparlament', r'\\boecd\\b', r'\\bfn\\b', r'internationell', r'global'\n",
    "    ],\n",
    "    'state_government': [\n",
    "        r'regering', r'staten', r'statlig', r'departement', r'minister', \n",
    "        r'myndighet', r'riksdag', r'förvaltning'\n",
    "    ],\n",
    "    'industry_business': [\n",
    "        r'företag', r'näringsliv', r'industri', r'bransch', r'arbetsgivare', \n",
    "        r'investera', r'startup', r'\\btech\\b', r'bolag', r'marknad'\n",
    "    ],\n",
    "    'experts_academia': [\n",
    "        r'forskare', r'forskni', r'universitet', r'högskola', r'expert', \n",
    "        r'vetenskap', r'akademi', r'professor'\n",
    "    ],\n",
    "    \n",
    "    # citizen-focused\n",
    "    'citizens_individuals': [\n",
    "        r'medborgare', r'individ', r'människa', r'person', r'användare', \n",
    "        r'konsument', r'patient', r'allmänhet'\n",
    "    ],\n",
    "    'workers_employees': [\n",
    "        r'arbetstagare', r'anställd', r'arbetare', r'personal', r'fackförbund', \n",
    "        r'\\bfack\\b', r'\\blo\\b', r'\\btco\\b', r'facklig'\n",
    "    ],\n",
    "    'communities_groups': [\n",
    "        r'samhälle', r'kommun', r'lokal', r'regional', r'civilsamhälle', \n",
    "        r'förening', r'organisation', r'medborgar'\n",
    "    ],\n",
    "    'vulnerable_groups': [\n",
    "        r'\\bbarn\\b', r'äldre', r'funktionsnedsättning', r'utsatt', r'marginaliserad', \n",
    "        r'minoritet', r'diskriminera', r'sårbar'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# compile regex patterns\n",
    "compiled_patterns = {}\n",
    "for category, keywords in stakeholder_keywords.items():\n",
    "    pattern = '|'.join(keywords)\n",
    "    compiled_patterns[category] = re.compile(pattern, re.IGNORECASE)\n",
    "\n",
    "print(\"stakeholder categories defined:\")\n",
    "print(\"\\ninstitutional actors:\")\n",
    "for cat in ['eu_international', 'state_government', 'industry_business', 'experts_academia']:\n",
    "    print(f\"  - {cat}: {len(stakeholder_keywords[cat])} keywords\")\n",
    "print(\"\\ncitizen-focused actors:\")\n",
    "for cat in ['citizens_individuals', 'workers_employees', 'communities_groups', 'vulnerable_groups']:\n",
    "    print(f\"  - {cat}: {len(stakeholder_keywords[cat])} keywords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stakeholder frequency analysis\n",
    "\n",
    "Count mentions of each stakeholder category and normalise by document length to enable comparison across documents of varying sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_stakeholder_mentions(text, patterns):\n",
    "    \"\"\"count mentions of each stakeholder category in text.\"\"\"\n",
    "    counts = {}\n",
    "    for category, pattern in patterns.items():\n",
    "        matches = pattern.findall(text)\n",
    "        counts[category] = len(matches)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# count stakeholder mentions for each document\nstakeholder_counts = []\n\nfor idx, row in df.iterrows():\n    counts = count_stakeholder_mentions(row['text_lower'], compiled_patterns)\n    stakeholder_counts.append(counts)\n\n# add counts to dataframe\ncounts_df = pd.DataFrame(stakeholder_counts)\ndf = pd.concat([df, counts_df], axis=1)\n\nprint(f\"analysed {len(df)} documents\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise by document length (per 1,000 words)\n",
    "stakeholder_categories = list(stakeholder_keywords.keys())\n",
    "\n",
    "for category in stakeholder_categories:\n",
    "    df[f'{category}_norm'] = (df[category] / df['word_count']) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate aggregate scores\n",
    "institutional_categories = ['eu_international', 'state_government', 'industry_business', 'experts_academia']\n",
    "citizen_categories = ['citizens_individuals', 'workers_employees', 'communities_groups', 'vulnerable_groups']\n",
    "\n",
    "df['institutional_total'] = df[institutional_categories].sum(axis=1)\n",
    "df['citizen_total'] = df[citizen_categories].sum(axis=1)\n",
    "\n",
    "df['institutional_norm'] = df[[f'{cat}_norm' for cat in institutional_categories]].sum(axis=1)\n",
    "df['citizen_norm'] = df[[f'{cat}_norm' for cat in citizen_categories]].sum(axis=1)\n",
    "\n",
    "# calculate institutional orientation score (positive = more institutional, negative = more citizen-focused)\n",
    "df['orientation_score'] = df['institutional_norm'] - df['citizen_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary statistics by document type\n",
    "summary_by_type = df.groupby('doc_type')[stakeholder_categories + ['institutional_total', 'citizen_total']].sum()\n",
    "print(\"total mentions by document type:\")\n",
    "print(summary_by_type)\n",
    "\n",
    "print(\"\\nmean normalised mentions per 1,000 words:\")\n",
    "norm_cols = [f'{cat}_norm' for cat in stakeholder_categories] + ['institutional_norm', 'citizen_norm']\n",
    "print(df.groupby('doc_type')[norm_cols].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisations\n",
    "\n",
    "Compare stakeholder invocation patterns between motioner and propositioner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# prepare data for plotting\nplot_data = df.groupby('doc_type')[[f'{cat}_norm' for cat in stakeholder_categories]].mean()\nplot_data.columns = [cat.replace('_', ' ').title() for cat in stakeholder_categories]\n\n# grouped bar chart\nfig, ax = plt.subplots(figsize=(12, 6))\nplot_data.T.plot(kind='bar', ax=ax, width=0.7, color=['#9B59B6', '#E91E63'])\n\nax.set_xlabel('')\nax.set_ylabel('mentions per 1,000 words')\nax.set_title('stakeholder category mentions by document type', fontsize=12, fontweight='normal')\nax.legend(title='document type', frameon=False)\nax.grid(axis='y', alpha=0.3, linestyle=':')\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\nplt.savefig('/Users/simon/Dropbox/wrk/active/research/riksdagen-data/swe-rd-ai/results/rq3_stakeholder_categories.png', \n            dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# stacked bar showing institutional vs citizen balance\nbalance_data = df.groupby('doc_type')[['institutional_norm', 'citizen_norm']].mean()\nbalance_data.columns = ['Institutional', 'Citizen-focused']\n\nfig, ax = plt.subplots(figsize=(8, 6))\nbalance_data.plot(kind='bar', stacked=True, ax=ax, color=['#9B59B6', '#E91E63'], width=0.6)\n\nax.set_xlabel('document type')\nax.set_ylabel('mentions per 1,000 words')\nax.set_title('institutional vs citizen-focused actor balance', fontsize=12, fontweight='normal')\nax.legend(title='actor type', frameon=False)\nax.grid(axis='y', alpha=0.3, linestyle=':')\nplt.xticks(rotation=0)\nplt.tight_layout()\nplt.savefig('/Users/simon/Dropbox/wrk/active/research/riksdagen-data/swe-rd-ai/results/rq3_actor_balance.png', \n            dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"\\nactor balance ratios (institutional:citizen):\")\nfor doc_type in balance_data.index:\n    inst = balance_data.loc[doc_type, 'Institutional']\n    cit = balance_data.loc[doc_type, 'Citizen-focused']\n    ratio = inst / cit if cit > 0 else float('inf')\n    print(f\"{doc_type}: {ratio:.2f}:1\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# scatter plot of institutional vs citizen scores\nfig, ax = plt.subplots(figsize=(10, 8))\n\nfor doc_type, color, label in [('mot', '#9B59B6', 'motioner'), ('prop', '#E91E63', 'propositioner')]:\n    subset = df[df['doc_type'] == doc_type]\n    ax.scatter(subset['institutional_norm'], subset['citizen_norm'], \n               alpha=0.5, s=30, color=color, label=label)\n\n# add diagonal reference line (equal balance)\nmax_val = max(df['institutional_norm'].max(), df['citizen_norm'].max())\nax.plot([0, max_val], [0, max_val], 'k--', alpha=0.3, linewidth=1, label='equal balance')\n\nax.set_xlabel('institutional actor mentions per 1,000 words')\nax.set_ylabel('citizen-focused actor mentions per 1,000 words')\nax.set_title('institutional vs citizen-focused orientation by document', fontsize=12, fontweight='normal')\nax.legend(frameon=False)\nax.grid(alpha=0.3, linestyle=':')\nplt.tight_layout()\nplt.savefig('/Users/simon/Dropbox/wrk/active/research/riksdagen-data/swe-rd-ai/results/rq3_orientation_scatter.png', \n            dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# distribution of orientation scores\nfig, ax = plt.subplots(figsize=(10, 6))\n\nfor doc_type, color, label in [('mot', '#9B59B6', 'motioner'), ('prop', '#E91E63', 'propositioner')]:\n    subset = df[df['doc_type'] == doc_type]['orientation_score']\n    ax.hist(subset, bins=30, alpha=0.6, color=color, label=label, edgecolor='white')\n\nax.axvline(0, color='black', linestyle='--', linewidth=1, alpha=0.5, label='neutral')\nax.set_xlabel('orientation score (institutional - citizen)')\nax.set_ylabel('number of documents')\nax.set_title('distribution of institutional orientation scores', fontsize=12, fontweight='normal')\nax.legend(frameon=False)\nax.grid(axis='y', alpha=0.3, linestyle=':')\nplt.tight_layout()\nplt.savefig('/Users/simon/Dropbox/wrk/active/research/riksdagen-data/swe-rd-ai/results/rq3_orientation_distribution.png', \n            dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"\\nmean orientation scores:\")\nprint(df.groupby('doc_type')['orientation_score'].describe()[['mean', 'std', 'min', 'max']])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical comparison\n",
    "\n",
    "Identify which stakeholder categories show the largest differences between document types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from scipy import stats\n\n# compare each category between document types\ncomparison_results = []\n\nfor category in stakeholder_categories:\n    mot_vals = df[df['doc_type'] == 'mot'][f'{category}_norm']\n    prop_vals = df[df['doc_type'] == 'prop'][f'{category}_norm']\n    \n    # mann-whitney u test (non-parametric)\n    statistic, pvalue = stats.mannwhitneyu(mot_vals, prop_vals, alternative='two-sided')\n    \n    # effect size (cohen's d)\n    mean_diff = mot_vals.mean() - prop_vals.mean()\n    pooled_std = np.sqrt((mot_vals.std()**2 + prop_vals.std()**2) / 2)\n    cohens_d = mean_diff / pooled_std if pooled_std > 0 else 0\n    \n    comparison_results.append({\n        'category': category,\n        'mot_mean': mot_vals.mean(),\n        'prop_mean': prop_vals.mean(),\n        'difference': mean_diff,\n        'cohens_d': cohens_d,\n        'p_value': pvalue,\n        'significant': pvalue < 0.05\n    })\n\ncomparison_df = pd.DataFrame(comparison_results)\ncomparison_df = comparison_df.sort_values('cohens_d', ascending=False)\n\nprint(\"stakeholder category comparison (motioner vs propositioner):\")\nprint(\"\\npositive difference = higher in motioner, negative = higher in propositioner\")\nprint(comparison_df.to_string(index=False))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# compare aggregate scores\nprint(\"\\naggregate actor type comparison:\")\nprint(\"\\ninstitutional actors:\")\nmot_inst = df[df['doc_type'] == 'mot']['institutional_norm']\nprop_inst = df[df['doc_type'] == 'prop']['institutional_norm']\nstat, pval = stats.mannwhitneyu(mot_inst, prop_inst)\nprint(f\"  motioner mean: {mot_inst.mean():.2f}\")\nprint(f\"  propositioner mean: {prop_inst.mean():.2f}\")\nprint(f\"  difference: {mot_inst.mean() - prop_inst.mean():.2f}\")\nprint(f\"  p-value: {pval:.4f}\")\n\nprint(\"\\ncitizen-focused actors:\")\nmot_cit = df[df['doc_type'] == 'mot']['citizen_norm']\nprop_cit = df[df['doc_type'] == 'prop']['citizen_norm']\nstat, pval = stats.mannwhitneyu(mot_cit, prop_cit)\nprint(f\"  motioner mean: {mot_cit.mean():.2f}\")\nprint(f\"  propositioner mean: {prop_cit.mean():.2f}\")\nprint(f\"  difference: {mot_cit.mean() - prop_cit.mean():.2f}\")\nprint(f\"  p-value: {pval:.4f}\")\n\nprint(\"\\norientation score:\")\nmot_orient = df[df['doc_type'] == 'mot']['orientation_score']\nprop_orient = df[df['doc_type'] == 'prop']['orientation_score']\nstat, pval = stats.mannwhitneyu(mot_orient, prop_orient)\nprint(f\"  motioner mean: {mot_orient.mean():.2f}\")\nprint(f\"  propositioner mean: {prop_orient.mean():.2f}\")\nprint(f\"  difference: {mot_orient.mean() - prop_orient.mean():.2f}\")\nprint(f\"  p-value: {pval:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export results\n",
    "\n",
    "Save document-level stakeholder data and category comparison statistics for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create results directory if needed\n",
    "results_dir = Path('/Users/simon/Dropbox/wrk/active/research/riksdagen-data/swe-rd-ai/results')\n",
    "results_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export document-level data\n",
    "export_cols = ['document_id', 'title', 'doc_type', 'date', 'parliamentary_year', 'word_count'] + \\\n",
    "              stakeholder_categories + \\\n",
    "              [f'{cat}_norm' for cat in stakeholder_categories] + \\\n",
    "              ['institutional_total', 'citizen_total', 'institutional_norm', 'citizen_norm', 'orientation_score']\n",
    "\n",
    "df[export_cols].to_csv(\n",
    "    results_dir / 'rq3_document_stakeholders.csv',\n",
    "    index=False,\n",
    "    encoding='utf-8'\n",
    ")\n",
    "\n",
    "print(f\"exported document-level data: {len(df)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export category comparison\n",
    "comparison_df.to_csv(\n",
    "    results_dir / 'rq3_stakeholder_comparison.csv',\n",
    "    index=False,\n",
    "    encoding='utf-8'\n",
    ")\n",
    "\n",
    "print(f\"exported stakeholder comparison: {len(comparison_df)} categories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# summary statistics for quick reference\nsummary = {\n    'corpus_stats': {\n        'total_documents': len(df),\n        'motioner': len(df[df['doc_type'] == 'mot']),\n        'propositioner': len(df[df['doc_type'] == 'prop']),\n        'total_words': int(df['word_count'].sum())\n    },\n    'mean_mentions_per_1k_words': {\n        'motioner': {\n            'institutional': float(df[df['doc_type'] == 'mot']['institutional_norm'].mean()),\n            'citizen_focused': float(df[df['doc_type'] == 'mot']['citizen_norm'].mean()),\n            'orientation_score': float(df[df['doc_type'] == 'mot']['orientation_score'].mean())\n        },\n        'propositioner': {\n            'institutional': float(df[df['doc_type'] == 'prop']['institutional_norm'].mean()),\n            'citizen_focused': float(df[df['doc_type'] == 'prop']['citizen_norm'].mean()),\n            'orientation_score': float(df[df['doc_type'] == 'prop']['orientation_score'].mean())\n        }\n    }\n}\n\nimport json\nwith open(results_dir / 'rq3_summary.json', 'w', encoding='utf-8') as f:\n    json.dump(summary, f, indent=2, ensure_ascii=False)\n\nprint(\"exported summary statistics\")\nprint(f\"\\nkey findings:\")\nprint(f\"  motioner orientation: {summary['mean_mentions_per_1k_words']['motioner']['orientation_score']:.2f}\")\nprint(f\"  propositioner orientation: {summary['mean_mentions_per_1k_words']['propositioner']['orientation_score']:.2f}\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}