{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ4: Temporal emergence of AI discourse\n",
    "\n",
    "This notebook analyses how AI discourse has emerged and intensified over time in Swedish parliamentary documents, comparing motioner (MP proposals) with propositioner (government bills) to identify which document type leads the discourse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# set visualisation style\n",
    "plt.rcParams['font.family'] = 'monospace'\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 10\n",
    "sns.set_palette(['#9b59b6', '#e91e63'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_document(file_path):\n",
    "    \"\"\"extract metadata and clean text from a parliamentary document file.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # split metadata from content\n",
    "    parts = content.split('=' * 80, 1)\n",
    "    if len(parts) != 2:\n",
    "        return None\n",
    "    \n",
    "    metadata_text, html_content = parts\n",
    "    \n",
    "    # extract metadata fields\n",
    "    metadata = {}\n",
    "    for line in metadata_text.strip().split('\\n'):\n",
    "        if ':' in line:\n",
    "            key, value = line.split(':', 1)\n",
    "            metadata[key.strip().lower().replace(' ', '_')] = value.strip()\n",
    "    \n",
    "    # extract plain text from HTML\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    text = soup.get_text(separator=' ', strip=True)\n",
    "    \n",
    "    # remove scanning disclaimers\n",
    "    text = re.sub(r'Observera att dokumentet är inskannat.*?förekomma\\.?', '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    return {\n",
    "        'document_id': metadata.get('document_id', ''),\n",
    "        'title': metadata.get('title', ''),\n",
    "        'date': metadata.get('date', ''),\n",
    "        'parliamentary_year': metadata.get('parliamentary_year', ''),\n",
    "        'text': text.strip()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load motioner\n",
    "mot_dir = Path('/Users/simon/Dropbox/wrk/active/research/riksdagen-data/swe-rd-ai/data/motioner')\n",
    "mot_files = list(mot_dir.glob('*.txt'))\n",
    "\n",
    "mot_data = []\n",
    "for file_path in mot_files:\n",
    "    doc = parse_document(file_path)\n",
    "    if doc:\n",
    "        doc['doc_type'] = 'mot'\n",
    "        mot_data.append(doc)\n",
    "\n",
    "print(f\"Loaded {len(mot_data)} motioner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load propositioner\n",
    "prop_dir = Path('/Users/simon/Dropbox/wrk/active/research/riksdagen-data/swe-rd-ai/data/propositioner')\n",
    "prop_files = list(prop_dir.glob('*.txt'))\n",
    "\n",
    "prop_data = []\n",
    "for file_path in prop_files:\n",
    "    doc = parse_document(file_path)\n",
    "    if doc:\n",
    "        doc['doc_type'] = 'prop'\n",
    "        prop_data.append(doc)\n",
    "\n",
    "print(f\"Loaded {len(prop_data)} propositioner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine into single dataframe\n",
    "df = pd.DataFrame(mot_data + prop_data)\n",
    "print(f\"Total documents: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal parsing and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year(parliamentary_year):\n",
    "    \"\"\"extract primary year from parliamentary year format (e.g., '2023/24' -> 2023).\"\"\"\n",
    "    if not parliamentary_year:\n",
    "        return None\n",
    "    match = re.match(r'(\\d{4})', parliamentary_year)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "df['year'] = df['parliamentary_year'].apply(extract_year)\n",
    "\n",
    "# remove rows without valid year\n",
    "df = df.dropna(subset=['year'])\n",
    "df['year'] = df['year'].astype(int)\n",
    "\n",
    "print(f\"Year range: {df['year'].min()} - {df['year'].max()}\")\n",
    "print(f\"Documents with valid year: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focus on 2010 onwards where AI discourse intensifies\n",
    "df_filtered = df[df['year'] >= 2010].copy()\n",
    "print(f\"Documents from 2010 onwards: {len(df_filtered)}\")\n",
    "print(f\"\\nYear distribution:\")\n",
    "print(df_filtered['year'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI mention analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ai_mentions(text):\n",
    "    \"\"\"count occurrences of AI-related terms in text.\"\"\"\n",
    "    if not text:\n",
    "        return 0\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    patterns = [\n",
    "        r'\\bai\\b',\n",
    "        r'artificiell intelligens',\n",
    "        r'maskininlärning',\n",
    "        r'djupinlärning'\n",
    "    ]\n",
    "    \n",
    "    total = 0\n",
    "    for pattern in patterns:\n",
    "        total += len(re.findall(pattern, text_lower))\n",
    "    \n",
    "    return total\n",
    "\n",
    "def count_words(text):\n",
    "    \"\"\"count total words in text.\"\"\"\n",
    "    if not text:\n",
    "        return 0\n",
    "    return len(re.findall(r'\\b\\w+\\b', text))\n",
    "\n",
    "df_filtered['ai_mentions'] = df_filtered['text'].apply(count_ai_mentions)\n",
    "df_filtered['word_count'] = df_filtered['text'].apply(count_words)\n",
    "df_filtered['ai_density'] = (df_filtered['ai_mentions'] / df_filtered['word_count'] * 1000).round(2)\n",
    "\n",
    "# handle division by zero\n",
    "df_filtered['ai_density'] = df_filtered['ai_density'].replace([np.inf, -np.inf], 0)\n",
    "\n",
    "print(f\"Summary statistics:\")\n",
    "print(df_filtered[['ai_mentions', 'word_count', 'ai_density']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document volume over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count documents per year by type\n",
    "volume_by_year = df_filtered.groupby(['year', 'doc_type']).size().unstack(fill_value=0)\n",
    "volume_by_year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise volume trends\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.plot(volume_by_year.index, volume_by_year['mot'], \n",
    "        marker='o', linewidth=2, label='motioner', color='#9b59b6')\n",
    "ax.plot(volume_by_year.index, volume_by_year['prop'], \n",
    "        marker='s', linewidth=2, label='propositioner', color='#e91e63')\n",
    "\n",
    "ax.set_xlabel('year')\n",
    "ax.set_ylabel('document count')\n",
    "ax.set_title('AI-related parliamentary documents over time')\n",
    "ax.legend(frameon=False)\n",
    "ax.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate year-over-year growth rates\n",
    "growth_rates = volume_by_year.pct_change() * 100\n",
    "growth_rates = growth_rates.round(1)\n",
    "\n",
    "print(\"Year-over-year growth rates (%):\")\n",
    "print(growth_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discourse intensity over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean AI mention density per year by type\n",
    "intensity_by_year = df_filtered.groupby(['year', 'doc_type'])['ai_density'].mean().unstack()\n",
    "intensity_by_year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# visualise intensity trends (from 2016 onwards)\nintensity_recent = intensity_by_year[intensity_by_year.index >= 2016]\n\nfig, ax = plt.subplots(figsize=(12, 6))\n\nax.plot(intensity_recent.index, intensity_recent['mot'], \n        marker='o', linewidth=2, label='motioner', color='#9b59b6')\nax.plot(intensity_recent.index, intensity_recent['prop'], \n        marker='s', linewidth=2, label='propositioner', color='#e91e63')\n\nax.set_xlabel('year')\nax.set_ylabel('AI mentions per 1,000 words')\nax.set_title('AI discourse intensity over time')\nax.legend(frameon=False)\nax.grid(True, alpha=0.3, linestyle='--')\n\nplt.tight_layout()\n\n# save to results\nresults_dir = Path('/Users/simon/Dropbox/wrk/active/research/riksdagen-data/swe-rd-ai/results')\nfig.savefig(results_dir / 'rq4_intensity.png', dpi=150, bbox_inches='tight', facecolor='white')\nprint(f\"Saved to {results_dir / 'rq4_intensity.png'}\")\n\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative document growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cumulative sums\n",
    "cumulative_volume = volume_by_year.cumsum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.fill_between(cumulative_volume.index, 0, cumulative_volume['mot'], \n",
    "                 alpha=0.7, label='motioner', color='#9b59b6')\n",
    "ax.fill_between(cumulative_volume.index, cumulative_volume['mot'], \n",
    "                 cumulative_volume['mot'] + cumulative_volume['prop'],\n",
    "                 alpha=0.7, label='propositioner', color='#e91e63')\n",
    "\n",
    "ax.set_xlabel('year')\n",
    "ax.set_ylabel('cumulative document count')\n",
    "ax.set_title('Cumulative growth of AI discourse corpus')\n",
    "ax.legend(frameon=False)\n",
    "ax.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lead/lag analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify first occurrence of AI discourse by document type\n",
    "first_mot = df_filtered[df_filtered['doc_type'] == 'mot']['year'].min()\n",
    "first_prop = df_filtered[df_filtered['doc_type'] == 'prop']['year'].min()\n",
    "\n",
    "print(f\"First AI mention in motioner: {first_mot}\")\n",
    "print(f\"First AI mention in propositioner: {first_prop}\")\n",
    "print(f\"\\nLead time: {abs(first_mot - first_prop)} years\")\n",
    "\n",
    "if first_mot < first_prop:\n",
    "    print(\"Motioner lead the discourse\")\n",
    "elif first_prop < first_mot:\n",
    "    print(\"Propositioner lead the discourse\")\n",
    "else:\n",
    "    print(\"Both document types emerged simultaneously\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify inflection points (year with highest growth rate)\n",
    "print(\"\\nInflection points (highest growth rates):\")\n",
    "print(f\"\\nMotioner peak growth: {growth_rates['mot'].idxmax()} ({growth_rates['mot'].max():.1f}%)\")\n",
    "print(f\"Propositioner peak growth: {growth_rates['prop'].idxmax()} ({growth_rates['prop'].max():.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation between mot and prop trends\n",
    "correlation = volume_by_year['mot'].corr(volume_by_year['prop'])\n",
    "print(f\"\\nCorrelation between motioner and propositioner volume: {correlation:.3f}\")\n",
    "\n",
    "intensity_correlation = intensity_by_year['mot'].corr(intensity_by_year['prop'])\n",
    "print(f\"Correlation between motioner and propositioner intensity: {intensity_correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotated timeline with key events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create annotated timeline\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "ax.plot(volume_by_year.index, volume_by_year['mot'], \n",
    "        marker='o', linewidth=2, label='motioner', color='#9b59b6')\n",
    "ax.plot(volume_by_year.index, volume_by_year['prop'], \n",
    "        marker='s', linewidth=2, label='propositioner', color='#e91e63')\n",
    "\n",
    "# annotate key events\n",
    "events = [\n",
    "    (2016, 'EU AI discussion begins'),\n",
    "    (2018, 'Swedish AI strategy'),\n",
    "    (2021, 'EU AI Act proposal'),\n",
    "    (2022, 'ChatGPT launch')\n",
    "]\n",
    "\n",
    "for year, event in events:\n",
    "    if year in volume_by_year.index:\n",
    "        y_max = max(volume_by_year.loc[year, 'mot'], volume_by_year.loc[year, 'prop'])\n",
    "        ax.axvline(x=year, color='gray', linestyle=':', alpha=0.5)\n",
    "        ax.text(year, y_max + 5, event, rotation=45, \n",
    "                ha='left', va='bottom', fontsize=8, color='gray')\n",
    "\n",
    "ax.set_xlabel('year')\n",
    "ax.set_ylabel('document count')\n",
    "ax.set_title('AI discourse timeline with key events')\n",
    "ax.legend(frameon=False)\n",
    "ax.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarise key findings\n",
    "summary = {\n",
    "    'metric': [],\n",
    "    'motioner': [],\n",
    "    'propositioner': []\n",
    "}\n",
    "\n",
    "# total documents\n",
    "summary['metric'].append('total_documents')\n",
    "summary['motioner'].append(len(df_filtered[df_filtered['doc_type'] == 'mot']))\n",
    "summary['propositioner'].append(len(df_filtered[df_filtered['doc_type'] == 'prop']))\n",
    "\n",
    "# first appearance\n",
    "summary['metric'].append('first_year')\n",
    "summary['motioner'].append(first_mot)\n",
    "summary['propositioner'].append(first_prop)\n",
    "\n",
    "# peak year (by volume)\n",
    "summary['metric'].append('peak_volume_year')\n",
    "summary['motioner'].append(volume_by_year['mot'].idxmax())\n",
    "summary['propositioner'].append(volume_by_year['prop'].idxmax())\n",
    "\n",
    "# peak volume\n",
    "summary['metric'].append('peak_volume_count')\n",
    "summary['motioner'].append(volume_by_year['mot'].max())\n",
    "summary['propositioner'].append(volume_by_year['prop'].max())\n",
    "\n",
    "# mean intensity\n",
    "summary['metric'].append('mean_ai_density')\n",
    "summary['motioner'].append(df_filtered[df_filtered['doc_type'] == 'mot']['ai_density'].mean().round(2))\n",
    "summary['propositioner'].append(df_filtered[df_filtered['doc_type'] == 'prop']['ai_density'].mean().round(2))\n",
    "\n",
    "# average annual growth (excluding first year)\n",
    "summary['metric'].append('avg_growth_rate_pct')\n",
    "summary['motioner'].append(growth_rates['mot'][1:].mean().round(1))\n",
    "summary['propositioner'].append(growth_rates['prop'][1:].mean().round(1))\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "print(\"Summary statistics:\")\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify breakthrough year (when cumulative docs exceed 50)\n",
    "breakthrough_mot = cumulative_volume[cumulative_volume['mot'] >= 50].index.min()\n",
    "breakthrough_prop = cumulative_volume[cumulative_volume['prop'] >= 50].index.min()\n",
    "\n",
    "print(f\"\\nBreakthrough year (50+ cumulative documents):\")\n",
    "print(f\"Motioner: {breakthrough_mot}\")\n",
    "print(f\"Propositioner: {breakthrough_prop}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare export data\n",
    "export_data = []\n",
    "\n",
    "for year in volume_by_year.index:\n",
    "    export_data.append({\n",
    "        'year': year,\n",
    "        'mot_count': volume_by_year.loc[year, 'mot'],\n",
    "        'prop_count': volume_by_year.loc[year, 'prop'],\n",
    "        'mot_intensity': intensity_by_year.loc[year, 'mot'],\n",
    "        'prop_intensity': intensity_by_year.loc[year, 'prop'],\n",
    "        'mot_cumulative': cumulative_volume.loc[year, 'mot'],\n",
    "        'prop_cumulative': cumulative_volume.loc[year, 'prop']\n",
    "    })\n",
    "\n",
    "export_df = pd.DataFrame(export_data)\n",
    "\n",
    "# ensure results directory exists\n",
    "results_dir = Path('/Users/simon/Dropbox/wrk/active/research/riksdagen-data/swe-rd-ai/results')\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# save to csv\n",
    "output_path = results_dir / 'rq4_temporal_trends.csv'\n",
    "export_df.to_csv(output_path, index=False)\n",
    "print(f\"Results saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}