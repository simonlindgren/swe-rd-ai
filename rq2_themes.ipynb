{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# RQ2: Policy domain analysis\n",
    "\n",
    "This notebook analyses which policy domains dominate in different document types. We compare motioner (bottom-up MP proposals) and propositioner (top-down government bills) across eight policy domains, testing whether government bills focus more on competitiveness and innovation whilst motioner emphasise ethics and social impacts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# configure visualisation defaults\n",
    "plt.rcParams['font.family'] = 'monospace'\n",
    "plt.rcParams['font.size'] = 10\n",
    "sns.set_palette(['#9b59b6', '#e91e63', '#34495e', '#95a5a6'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "Load all documents from both directories and parse their metadata headers to create a structured dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_document(filepath):\n",
    "    \"\"\"extract metadata and content from a parliamentary document file.\"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # split header from content\n",
    "    parts = content.split('=' * 80)\n",
    "    if len(parts) < 2:\n",
    "        return None\n",
    "    \n",
    "    header = parts[0]\n",
    "    doc_content = parts[1].strip()\n",
    "    \n",
    "    # extract metadata fields\n",
    "    metadata = {}\n",
    "    for line in header.strip().split('\\n'):\n",
    "        if ':' in line:\n",
    "            key, value = line.split(':', 1)\n",
    "            metadata[key.strip().lower()] = value.strip()\n",
    "    \n",
    "    return {\n",
    "        'doc_id': metadata.get('document id', ''),\n",
    "        'title': metadata.get('title', ''),\n",
    "        'date': metadata.get('date', ''),\n",
    "        'year': metadata.get('parliamentary year', ''),\n",
    "        'search_term': metadata.get('search term', ''),\n",
    "        'content': doc_content,\n",
    "        'filepath': str(filepath)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load motioner\n",
    "mot_dir = Path('/Users/simon/Dropbox/wrk/active/research/riksdagen-data/swe-rd-ai/data/motioner')\n",
    "mot_files = list(mot_dir.glob('*.txt'))\n",
    "mot_docs = [parse_document(f) for f in mot_files]\n",
    "mot_docs = [doc for doc in mot_docs if doc is not None]\n",
    "\n",
    "for doc in mot_docs:\n",
    "    doc['doc_type'] = 'mot'\n",
    "\n",
    "# load propositioner\n",
    "prop_dir = Path('/Users/simon/Dropbox/wrk/active/research/riksdagen-data/swe-rd-ai/data/propositioner')\n",
    "prop_files = list(prop_dir.glob('*.txt'))\n",
    "prop_docs = [parse_document(f) for f in prop_files]\n",
    "prop_docs = [doc for doc in prop_docs if doc is not None]\n",
    "\n",
    "for doc in prop_docs:\n",
    "    doc['doc_type'] = 'prop'\n",
    "\n",
    "# combine into dataframe\n",
    "all_docs = mot_docs + prop_docs\n",
    "df = pd.DataFrame(all_docs)\n",
    "\n",
    "print(f\"loaded {len(mot_docs)} motioner and {len(prop_docs)} propositioner\")\n",
    "print(f\"total documents: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Text preprocessing\n",
    "\n",
    "Remove HTML tags and extract clean text for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html(html_text):\n",
    "    \"\"\"remove html tags and extract plain text.\"\"\"\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "    # normalise whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df['clean_text'] = df['content'].apply(clean_html)\n",
    "df['word_count'] = df['clean_text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "print(f\"average document length: {df['word_count'].mean():.0f} words\")\n",
    "df.groupby('doc_type')['word_count'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Policy domain dictionaries\n",
    "\n",
    "Define Swedish keyword lists for eight policy domains relevant to AI discourse. Keywords capture both direct mentions and related concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define policy domain dictionaries with swedish keywords\n",
    "policy_domains = {\n",
    "    'labour': [\n",
    "        'arbete', 'arbetslöshet', 'sysselsättning', 'anställning', 'jobb',\n",
    "        'arbetsmarknad', 'arbetskraft', 'yrke', 'kompetens', 'lön',\n",
    "        'arbetsgivare', 'arbetstagare', 'fackförbund', 'fack', 'anställd'\n",
    "    ],\n",
    "    'education': [\n",
    "        'utbildning', 'skola', 'universitet', 'högskola', 'lärande',\n",
    "        'undervisning', 'kunskap', 'forskning', 'student', 'elev',\n",
    "        'lärare', 'pedagog', 'kurs', 'yrkesutbildning', 'vidareutbildning'\n",
    "    ],\n",
    "    'healthcare': [\n",
    "        'hälsa', 'vård', 'sjukvård', 'omsorg', 'patient', 'medicin',\n",
    "        'behandling', 'diagnos', 'sjukhus', 'vårdcentral', 'äldreomsorg',\n",
    "        'hälso', 'medicinsk', 'klinik', 'läkare'\n",
    "    ],\n",
    "    'defence': [\n",
    "        'försvar', 'säkerhet', 'militär', 'cyber', 'hot', 'terrorism',\n",
    "        'beredskap', 'försvarsmakt', 'säkerhetspolisen', 'must',\n",
    "        'cybersäkerhet', 'terrorhot', 'krishantering', 'totalförsvar'\n",
    "    ],\n",
    "    'innovation': [\n",
    "        'innovation', 'näringsliv', 'företag', 'startup', 'tillväxt',\n",
    "        'konkurrens', 'industri', 'digitalisering', 'export', 'investering',\n",
    "        'konkurrenskraft', 'produktivitet', 'affär', 'marknad', 'ekonomi'\n",
    "    ],\n",
    "    'ethics': [\n",
    "        'etik', 'integritet', 'rättighet', 'demokrati', 'transparens',\n",
    "        'ansvar', 'diskriminering', 'jämlikhet', 'jämställdhet', 'mänsklig',\n",
    "        'gdpr', 'personuppgift', 'datasky dd', 'fördom', 'bias'\n",
    "    ],\n",
    "    'environment': [\n",
    "        'miljö', 'klimat', 'hållbar', 'energi', 'utsläpp', 'klimatmål',\n",
    "        'klimatförändring', 'klimatpåverkan', 'fossilfri', 'förnybar',\n",
    "        'koldioxid', 'hållbarhet', 'ekologi', 'grön'\n",
    "    ],\n",
    "    'public_sector': [\n",
    "        'myndighet', 'offentlig', 'förvaltning', 'kommun', 'region',\n",
    "        'stat', 'statlig', 'kommunal', 'digital förvaltning', 'e-förvaltning',\n",
    "        'service', 'välfärd', 'myndighetsutövning', 'landsting'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# display domain sizes\n",
    "for domain, keywords in policy_domains.items():\n",
    "    print(f\"{domain}: {len(keywords)} keywords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Domain frequency analysis\n",
    "\n",
    "Count domain keyword occurrences in each document and normalise by document length to enable fair comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_domain_words(text, word_list):\n",
    "    \"\"\"count occurrences of domain keywords in text.\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    count = 0\n",
    "    for word in word_list:\n",
    "        # word boundary matching with suffix tolerance\n",
    "        count += len(re.findall(r'\\b' + word + r'\\w*\\b', text_lower))\n",
    "    return count\n",
    "\n",
    "# calculate domain frequencies for each document\n",
    "for domain, keywords in policy_domains.items():\n",
    "    # raw counts\n",
    "    df[f'{domain}_count'] = df['clean_text'].apply(lambda x: count_domain_words(x, keywords))\n",
    "    # normalised per 1000 words\n",
    "    df[f'{domain}_per_1k'] = (df[f'{domain}_count'] / df['word_count']) * 1000\n",
    "\n",
    "# display sample\n",
    "domain_cols = [f'{d}_per_1k' for d in policy_domains.keys()]\n",
    "df[['doc_id', 'doc_type'] + domain_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Domain profiles by document type\n",
    "\n",
    "Calculate mean domain frequencies for each document type to identify characteristic patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate domain frequencies by document type\n",
    "domain_summary = df.groupby('doc_type')[[f'{d}_per_1k' for d in policy_domains.keys()]].mean()\n",
    "\n",
    "# rename columns for clarity\n",
    "domain_summary.columns = list(policy_domains.keys())\n",
    "\n",
    "# transpose for better readability\n",
    "domain_summary_t = domain_summary.T\n",
    "domain_summary_t.columns = ['motioner', 'propositioner']\n",
    "\n",
    "# calculate difference (mot - prop)\n",
    "domain_summary_t['difference'] = domain_summary_t['motioner'] - domain_summary_t['propositioner']\n",
    "\n",
    "# sort by absolute difference\n",
    "domain_summary_t['abs_diff'] = domain_summary_t['difference'].abs()\n",
    "domain_summary_t = domain_summary_t.sort_values('abs_diff', ascending=False)\n",
    "\n",
    "domain_summary_t.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Visualisations\n",
    "\n",
    "Create comparative visualisations showing domain profiles and their distribution across document types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped bar chart comparing domain frequencies\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "domains = list(policy_domains.keys())\n",
    "x = np.arange(len(domains))\n",
    "width = 0.35\n",
    "\n",
    "mot_means = [df[df['doc_type'] == 'mot'][f'{d}_per_1k'].mean() for d in domains]\n",
    "prop_means = [df[df['doc_type'] == 'prop'][f'{d}_per_1k'].mean() for d in domains]\n",
    "\n",
    "ax.bar(x - width/2, mot_means, width, label='motioner', color='#9b59b6')\n",
    "ax.bar(x + width/2, prop_means, width, label='propositioner', color='#e91e63')\n",
    "\n",
    "ax.set_xlabel('policy domain')\n",
    "ax.set_ylabel('mean frequency (per 1000 words)')\n",
    "ax.set_title('policy domain frequencies by document type')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(domains, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap showing domain co-occurrence patterns\n",
    "# calculate correlation matrix of domain frequencies\n",
    "domain_freq_cols = [f'{d}_per_1k' for d in policy_domains.keys()]\n",
    "correlation_matrix = df[domain_freq_cols].corr()\n",
    "\n",
    "# rename for clarity\n",
    "correlation_matrix.columns = list(policy_domains.keys())\n",
    "correlation_matrix.index = list(policy_domains.keys())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "sns.heatmap(\n",
    "    correlation_matrix,\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    cmap='RdPu',\n",
    "    square=True,\n",
    "    cbar_kws={'label': 'correlation coefficient'},\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ax.set_title('domain co-occurrence patterns (correlation matrix)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# radar chart showing domain profiles\n",
    "from math import pi\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
    "\n",
    "# prepare data\n",
    "domains = list(policy_domains.keys())\n",
    "angles = [n / len(domains) * 2 * pi for n in range(len(domains))]\n",
    "angles += angles[:1]  # complete the circle\n",
    "\n",
    "mot_values = [df[df['doc_type'] == 'mot'][f'{d}_per_1k'].mean() for d in domains]\n",
    "prop_values = [df[df['doc_type'] == 'prop'][f'{d}_per_1k'].mean() for d in domains]\n",
    "\n",
    "mot_values += mot_values[:1]  # complete the circle\n",
    "prop_values += prop_values[:1]\n",
    "\n",
    "# plot\n",
    "ax.plot(angles, mot_values, 'o-', linewidth=2, label='motioner', color='#9b59b6')\n",
    "ax.fill(angles, mot_values, alpha=0.15, color='#9b59b6')\n",
    "\n",
    "ax.plot(angles, prop_values, 'o-', linewidth=2, label='propositioner', color='#e91e63')\n",
    "ax.fill(angles, prop_values, alpha=0.15, color='#e91e63')\n",
    "\n",
    "# configure axes\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(domains)\n",
    "ax.set_ylim(0, max(max(mot_values), max(prop_values)) * 1.1)\n",
    "ax.set_title('policy domain profiles by document type', y=1.08)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Statistical comparison\n",
    "\n",
    "Identify which domains show the strongest over-representation or under-representation in each document type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate over/under-representation ratios\n",
    "comparison = pd.DataFrame({\n",
    "    'domain': list(policy_domains.keys()),\n",
    "    'mot_mean': [df[df['doc_type'] == 'mot'][f'{d}_per_1k'].mean() for d in policy_domains.keys()],\n",
    "    'prop_mean': [df[df['doc_type'] == 'prop'][f'{d}_per_1k'].mean() for d in policy_domains.keys()],\n",
    "    'mot_median': [df[df['doc_type'] == 'mot'][f'{d}_per_1k'].median() for d in policy_domains.keys()],\n",
    "    'prop_median': [df[df['doc_type'] == 'prop'][f'{d}_per_1k'].median() for d in policy_domains.keys()]\n",
    "})\n",
    "\n",
    "# calculate differences and ratios\n",
    "comparison['diff'] = comparison['mot_mean'] - comparison['prop_mean']\n",
    "comparison['ratio'] = comparison['mot_mean'] / comparison['prop_mean']\n",
    "\n",
    "# add interpretation\n",
    "comparison['favours'] = comparison['diff'].apply(\n",
    "    lambda x: 'motioner' if x > 0 else 'propositioner'\n",
    ")\n",
    "\n",
    "# sort by absolute difference\n",
    "comparison['abs_diff'] = comparison['diff'].abs()\n",
    "comparison = comparison.sort_values('abs_diff', ascending=False)\n",
    "\n",
    "comparison.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation: domain differences (mot - prop)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "comparison_sorted = comparison.sort_values('diff')\n",
    "colors = ['#9b59b6' if x > 0 else '#e91e63' for x in comparison_sorted['diff']]\n",
    "\n",
    "ax.barh(comparison_sorted['domain'], comparison_sorted['diff'], color=colors, alpha=0.7)\n",
    "ax.axvline(0, color='#34495e', linewidth=1, linestyle='--')\n",
    "\n",
    "ax.set_xlabel('difference in frequency (motioner - propositioner per 1k words)')\n",
    "ax.set_ylabel('policy domain')\n",
    "ax.set_title('domain over/under-representation by document type')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='#9b59b6', alpha=0.7, label='more in motioner'),\n",
    "    Patch(facecolor='#e91e63', alpha=0.7, label='more in propositioner')\n",
    "]\n",
    "ax.legend(handles=legend_elements)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Summary statistics\n",
    "\n",
    "Generate interpretable summary of domain distribution patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"POLICY DOMAIN ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\ntotal documents analysed: {len(df)}\")\n",
    "print(f\"  - motioner: {len(df[df['doc_type'] == 'mot'])}\")\n",
    "print(f\"  - propositioner: {len(df[df['doc_type'] == 'prop'])}\")\n",
    "\n",
    "print(\"\\ntop 3 domains in motioner:\")\n",
    "mot_top = comparison.sort_values('mot_mean', ascending=False).head(3)\n",
    "for idx, row in mot_top.iterrows():\n",
    "    print(f\"  {row['domain']}: {row['mot_mean']:.2f} per 1k words\")\n",
    "\n",
    "print(\"\\ntop 3 domains in propositioner:\")\n",
    "prop_top = comparison.sort_values('prop_mean', ascending=False).head(3)\n",
    "for idx, row in prop_top.iterrows():\n",
    "    print(f\"  {row['domain']}: {row['prop_mean']:.2f} per 1k words\")\n",
    "\n",
    "print(\"\\ndomains most over-represented in motioner (vs propositioner):\")\n",
    "mot_over = comparison.sort_values('diff', ascending=False).head(3)\n",
    "for idx, row in mot_over.iterrows():\n",
    "    print(f\"  {row['domain']}: +{row['diff']:.2f} per 1k words\")\n",
    "\n",
    "print(\"\\ndomains most over-represented in propositioner (vs motioner):\")\n",
    "prop_over = comparison.sort_values('diff').head(3)\n",
    "for idx, row in prop_over.iterrows():\n",
    "    print(f\"  {row['domain']}: {row['diff']:.2f} per 1k words\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Export results\n",
    "\n",
    "Save document-level domain frequencies and aggregate comparisons for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output directory\n",
    "output_dir = Path('/Users/simon/Dropbox/wrk/active/research/riksdagen-data/swe-rd-ai/results')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# export document-level domain frequencies\n",
    "export_cols = ['doc_id', 'doc_type', 'title', 'date', 'year', 'word_count'] + \\\n",
    "              [f'{d}_per_1k' for d in policy_domains.keys()]\n",
    "df[export_cols].to_csv(output_dir / 'rq2_document_themes.csv', index=False)\n",
    "\n",
    "# export domain comparison summary\n",
    "comparison[['domain', 'mot_mean', 'prop_mean', 'mot_median', 'prop_median', \n",
    "            'diff', 'ratio', 'favours']].to_csv(\n",
    "    output_dir / 'rq2_domain_comparison.csv', index=False\n",
    ")\n",
    "\n",
    "print(f\"results exported to {output_dir}\")\n",
    "print(f\"  - rq2_document_themes.csv ({len(df)} documents)\")\n",
    "print(f\"  - rq2_domain_comparison.csv ({len(comparison)} domains)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
